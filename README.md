# 대용량 데이터 처리 시스템 프로잭트

## 프로젝트 소개

이 프로젝트는 대용량 데이터를 견고하게 처리하기 위한 다양한 기술과 최적화 전략을 실험하고 구현한 시스템입니다. 검색 최적화, 대용량 데이터 적재, 배치 처리 등 다양한 기술적 도전을 해결하는 방법을 탐구합니다.

## 기술 스택

### 백엔드
- **Java 21**: 최신 Java 기능 활용
- **Spring Boot 3.4.5**: 강력한 웹 애플리케이션 프레임워크
- **Spring Security**: 보안 및 인증 처리
- **Spring Data JPA**: 객체 지향적 데이터 접근
- **Spring Batch**: 대용량 데이터 배치 처리
- **JWT**: 토큰 기반 인증

### 데이터베이스 및 저장소
- **MySQL**: 관계형 데이터 영구 저장
- **MongoDB**: 대용량 로그 및 분석 데이터 저장
- **Elasticsearch**: 고성능 검색 엔진
- **Redis**: 캐싱 및 세션 관리

### 개발 도구
- **Gradle**: 의존성 관리 및 빌드 자동화
- **Swagger/OpenAPI**: API 문서화

## 주요 기능 및 구현 전략

### 1. 고성능 검색 시스템

#### 기술 선택 이유
- **Elasticsearch + Kibana + MySQL 하이브리드 접근법**: 각 기술의 장점을 활용하여 고성능 검색과 데이터 일관성을 모두 보장

#### 구현 및 최적화 전략
- **이벤트 기반 동기화**: MySQL의 데이터 변경(생성, 수정, 삭제)이 발생할 때 Elasticsearch에 자동 동기화
- **하이브리드 검색 패턴**:
   - Elasticsearch에서 초기 검색을 통해 관련 문서 ID만 빠르게 추출
   - 추출된 ID를 기반으로 MySQL에서 인덱스를 활용한 정확한 최신 데이터 조회
- **Elasticsearch Refresh 정책 최적화**: 실시간 검색과 인덱싱 성능 간의 균형 조정

### 2. 대용량 광고 데이터 처리 시스템

#### MongoDB 선택 이유
- **스키마리스 구조**: 광고 조회 데이터의 다양한 속성을 유연하게 저장
- **확장성**: 수평적 확장을 통한 대용량 데이터 처리 능력
- **집계 파이프라인**: 복잡한 데이터 분석과 집계를 효율적으로 수행
- **성능**: 대량의 쓰기 작업에 최적화된 성능
- **샤딩**: 대규모 데이터셋의 분산 저장 지원

#### Spring Batch를 활용한 데이터 집계 최적화
- **3단계 작업 파이프라인**: 준비, 집계, 저장 단계로 나누어 효율적인 배치 처리
- **메모리 사용 최적화**:
   - MongoDB 집계 파이프라인을 사용하여 데이터 처리를 DB 레벨에서 수행
   - 필요한 필드만 선택적으로 프로젝션하여 메모리 사용 최소화
   - `allowDiskUse: true` 설정으로 대용량 처리 시 디스크 활용
- **청크 기반 처리**: 일정 크기(500개)의 청크로 데이터를 처리하여 메모리 효율성 확보
- **MongoDB 최적화 기법**:
   - 인덱스 활용: 날짜 필드에 인덱스를 사용한 효율적인 필터링
   - 임시 컬렉션: 중간 결과를 저장하여 처리 단계 분리
   - 커서 관리: 적절한 배치 크기로 데이터 스트리밍
- **MySQL 배치 삽입**: JDBC 배치 작업을 통한 효율적인 데이터 삽입
- **재시도 메커니즘**: 실패 시 이전 데이터를 삭제하고 재실행하는 안전한 처리

### 3. 시스템 안정성을 위한 추가 최적화

- **타임존 관리**: 모든 시스템(JVM, MongoDB, MySQL)에서 일관된 Asia/Seoul 타임존 설정
- **비동기 처리**: 대용량 작업의 논블로킹 처리
- **UUID 처리 최적화**: 효율적인 MySQL BINARY(16) 저장을 위한 변환 처리
- **모니터링 및 로깅**: 배치 작업 진행 상황과 결과 추적을 위한 세부 로깅

## 성능 및 최적화 결과

- MongoDB 집계 파이프라인을 통해 일일 수천만 건의 광고 조회 데이터를 효율적으로 처리
- JdbcBatchItemWriter를 통한 최적화된 MySQL 배치 삽입으로 저장 성능 향상
- 메모리 사용량을 최소화하면서도 대용량 데이터 처리 가능

## 확장 계획

- 실시간 분석 대시보드 구현
- 머신러닝을 활용한 광고 추천 시스템 개발
- Kafka를 활용한 이벤트 기반 아키텍처로 확장